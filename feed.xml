<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://zihe33huang.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://zihe33huang.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-03-05T10:52:17+00:00</updated><id>https://zihe33huang.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Regression</title><link href="https://zihe33huang.github.io/blog/2023/Regression/" rel="alternate" type="text/html" title="Regression"/><published>2023-03-02T00:00:00+00:00</published><updated>2023-03-02T00:00:00+00:00</updated><id>https://zihe33huang.github.io/blog/2023/Regression</id><content type="html" xml:base="https://zihe33huang.github.io/blog/2023/Regression/"><![CDATA[<h1 id="linear-regression">Linear Regression</h1> <h2 id="types-of-machine-learning">Types of Machine Learning</h2> <ul> <li><strong>Supervised Learning</strong>: where there is an input <em>X</em>, and an output <em>Y</em> and the task is to learn the mapping from the input to the output <ul> <li><strong>Classification</strong>: when <em>Y</em> is a <strong>categorical</strong> variable (e.g. spam/not spam)</li> <li><strong>Regression</strong>: when <em>Y</em> is a <strong>continuous</strong> variable.</li> </ul> </li> <li><strong>Unsupervised Learning:</strong> there is only input <em>X</em>. The aim is to find regularities/structure in the input space. One method is called <em>clustering</em>, where the aim is to find clusters or groupings of input.</li> </ul> <h2 id="linear-regression-1">Linear Regression</h2> <p><img src="images/image-20230302224557667.png" alt="image-20230302224557667"/></p> <h4 id="the-model">The model</h4> <p>In regression, we would like to write the numeric <strong>output</strong>, called the ==<strong>dependent or response variable</strong>==, as a function of the <strong>input</strong>, called the ==<strong>independent or explanatory variable</strong>==(also known as features).</p> <h4 id="cost-function">Cost Function</h4> <ul> <li>Least squares estimation</li> <li> <p><img src="images/image-20230302225720066.png" alt="image-20230302225720066" style="zoom:33%;"/></p> </li> <li> <p><img src="images/image-20230302225742613.png" alt="image-20230302225742613" style="zoom: 25%;"/></p> </li> <li>Find the values of θ0 and θ1 which have minimum cost.</li> <li>θ0 is the intercept(截距) ; also referred to as bias in machine learning literature.</li> <li>θ1 is the slope of the line.</li> </ul> <h2 id="learning-process-for-supervised-learning">Learning Process for Supervised learning</h2> <ul> <li> <p>Define model: <img src="images/image-20230302230125731.png" alt="image-20230302230125731" style="zoom:25%;"/></p> </li> <li> <p>Build the cost function:<img src="images/image-20230302230149973.png" alt="image-20230302230149973" style="zoom:25%;"/></p> </li> <li> <p>Optimize the cost function to find the model’s parameters</p> <ul> <li> <p>Optimization algorithms: ① <strong>Gradient</strong>(斜率, 梯度) descent [梯度下降法] ② <strong>stochastic</strong>(随机) gradient descent.</p> </li> <li> <p>Normal equation (in linear and multiple regression)</p> </li> </ul> </li> <li> <p>Evaluation of the model</p> </li> </ul> <h4 id="gradient-descent-optimization">Gradient descent optimization</h4> <ul> <li> <p>Start with any initial values for parameters</p> </li> <li> <p>Changing parameters to reduce the cost</p> </li> <li> <p>Repeat until at the minimum</p> </li> <li> <p>We use the gradient to change parameters in the right direction so that cost is reduced.</p> <p><img src="images/image-20230302231142879.png" alt="image-20230302231142879" style="zoom:25%;"/></p> </li> </ul> <h4 id="gradient-descent-algorithm梯度下降法">Gradient descent algorithm(梯度下降法)</h4> <ul> <li>Parameter: θ<sub>0</sub> , θ<sub>1</sub></li> <li>Calculate: h(x) = θ<sub>0 </sub> + θ<sub>1</sub> x</li> <li> <p>The cost function is <img src="images/image-20230302231711362.png" alt="image-20230302231711362" style="zoom:25%;"/></p> </li> <li> <p>Repeat until <strong>convergence</strong>(收敛) <img src="images/image-20230302231840533.png" alt="image-20230302231840533" style="zoom:25%;"/></p> <p>All parameters are updated simultaneously</p> </li> <li> <p>α is the learning rate and controls the size of the steps.</p> </li> <li> <p>Linear regression partial derivatives (偏导数)</p> </li> <li> <p><strong>Property</strong>:</p> <ul> <li>Batch algorithm because each iteration looks at all the training data</li> <li>Simultaneously update parameters according to partial derivatives</li> <li>Can be slow to converge</li> <li>Each iteration is slow processing all the training data</li> <li>Feature scaling is a good idea</li> <li><strong>Easily vectorized to use parallel linear algebra libraries that can exploit parallelism</strong></li> </ul> </li> </ul> <h4 id="stochastic-gradient-descent-algorithm随机梯度下降法">Stochastic gradient descent algorithm(随机梯度下降法)</h4> <ul> <li> <p>Randomly shuffle training data</p> </li> <li> <p>repeat {</p> <p>​ for {</p> <p><img src="images/image-20230302233125159.png" alt="image-20230302233125159" style="zoom:25%;"/></p> <p>​ }</p> <p>}</p> </li> <li> <p>Can scale algorithms to much bigger training sets</p> </li> <li> <p>May require few passes through training set (~1 to10)</p> </li> <li> <p>Very little scope for parallelism</p> </li> </ul> <h4 id="mini-batch-gradient-descent">Mini-batch gradient descent</h4> <p>Hybrid between batch (update after all <em>m</em> records) and stochastic (update after 1 record)</p> <ul> <li> <p>Upgrade using batch algorithm every <em>b&lt;m</em> training records</p> </li> <li> <p>Supports exploitation of vectorization and hence parallelism</p> </li> </ul> <h4 id="normal-equations">Normal equations</h4> <ul> <li> <p>Analytic solution rather than iterative</p> </li> <li><em>n</em> features, <em>m</em> training records</li> <li> <p><img src="images/image-20230302233618395.png" alt="image-20230302233618395" style="zoom: 50%;"/></p> </li> <li>X is called the design matrix</li> <li>Cost Function: <img src="images/image-20230302234813426.png" alt="image-20230302234813426" style="zoom:33%;"/> <ul> <li>Firstly, representing cost function as a matrix form: <img src="images/image-20230302234913841.png" alt="image-20230302234913841" style="zoom:33%;"/></li> <li>Simplify: <img src="images/image-20230302234943868.png" alt="image-20230302234943868" style="zoom:33%;"/></li> <li>Now make use of multivariate calculus to find the partial derivative and make it equal to 0 in all directions. Then, we can get the θ we want.</li> </ul> </li> <li>https://zhuanlan.zhihu.com/p/60719445 推导过程</li> </ul> <h4 id="comparison-of-gradient-descent-and-normal-equation">Comparison of Gradient descent and normal equation</h4> <ul> <li><em>n</em> features, <em>m</em> training records</li> <li>Gradient descent <ul> <li>Need to choose α</li> <li>Iterative</li> <li>Works for large <em>n</em></li> <li>Used with many learning algorithms</li> </ul> </li> <li>Normal equation <ul> <li>No need to choose α</li> <li>No iterations required</li> <li>Inverting <em>n × n</em> matrix can be slow for large <em>n</em></li> <li>Only works with linear regression</li> </ul> </li> </ul>]]></content><author><name></name></author><summary type="html"><![CDATA[Linear Regression]]></summary></entry><entry><title type="html">Da_tools_techniques</title><link href="https://zihe33huang.github.io/blog/2023/DA_Tools_Techniques/" rel="alternate" type="text/html" title="Da_tools_techniques"/><published>2023-03-01T00:00:00+00:00</published><updated>2023-03-01T00:00:00+00:00</updated><id>https://zihe33huang.github.io/blog/2023/DA_Tools_Techniques</id><content type="html" xml:base="https://zihe33huang.github.io/blog/2023/DA_Tools_Techniques/"><![CDATA[<h1 id="numpy">NumPy</h1> <ul> <li> <p>Python provides built-in libraries for both multi-threading and multi-processing, with high level abstractions</p> </li> <li>NumExpr and NumPy can speed-up Python codes through vectorisation and multithreading, Numba can even make use of OpenMP threading, if installed.</li> <li>Some libraries offer a “<strong>njobs</strong>” option, such as sci-kit learn, which uses multiprocessing to parallelize ML training, though scaling is limited in practice.</li> <li>The Python GIL prevents true multi-threaded parallelism <ul> <li>However, each Python process has its own GIL.</li> <li>NumExpr and NumPy compile to native code, so avoid dealing with the GIL.</li> </ul> </li> </ul> <h1 id="apache-spark">Apache Spark</h1> <ul> <li><strong>Apache Spark</strong> is an engine for executing data engineering, data science, and machine learning on single-node machines or clusters (单机或集群都可以)</li> <li>Key features: <ul> <li>Streaming data</li> <li>Analytics</li> <li>Data science at Scale</li> <li>Machine Learning</li> </ul> </li> <li>Clusters: <ul> <li>Component: ① Driver Program ② Cluster Manager ③ Worker Nodes</li> <li><img src="images/image-20230303000427295.png" alt="image-20230303000427295" style="zoom:50%;"/></li> <li>Supported cluster manager: ① Hadoop YARN ② Apache Mesos ③ Kubernetes</li> </ul> </li> </ul> <h3 id="why-apache-spark">Why Apache Spark</h3> <ul> <li>Focuses on computation. In-memory storage for intermediate computations</li> <li>APIs for multiple programming languages. Java Scala Python SQL R</li> <li>Libraries for different type of workflows.</li> </ul> <h3 id="how-spark-operates">How Spark operates?</h3> <ul> <li><strong>Transformations</strong> create a new Spark data frame without altering the original one. They can additionally be divided into: <ul> <li><strong><em>Narrow transformations</em></strong>, take a single input partition and return a single output partition (e.g. <em>filter operation</em>).</li> <li><strong><em>Wide transformations</em></strong>, use multiple partitions and require reshuffling(重新洗牌) of the data (e.g. <em>groupby operation</em>).</li> </ul> </li> <li><strong>Actions</strong> are eagerly executed, and produce a value (e.g., the result of processing a series of <strong>Transformations</strong>). Example actions are “count”, “collect”, and “saveAsTextFile”</li> </ul> <h3 id="spark-data-api">Spark Data API</h3> <ul> <li><strong>Resilient Distributed Dataset (RDD)</strong> <ul> <li>General purpose.</li> <li>==<strong>Represents data partitioned across cluster, operated on in parallel.</strong>==</li> <li><strong>Transparently</strong> moves data around the cluster</li> <li>More suitable for ==<strong>unstructured</strong>== data</li> <li>Less optimized</li> <li>==<strong>Immutable</strong>.== Computation arranged as graph of RDD transformations, each <strong>creating a new one</strong></li> <li>Persisted <strong>in memory</strong>(存在内存中) so lower disk I/O requirements</li> <li>Supports reconstruction of lost data from source (efficient based on knowledge of computation graph)</li> </ul> </li> <li><strong>DataFrame</strong> <ul> <li>Tabular</li> <li>Schema based</li> <li>More suitable for==<strong>structured data</strong>==</li> <li><strong>More optimized</strong></li> </ul> </li> <li><strong>Dataset</strong> <ul> <li>Combination of both</li> </ul> </li> </ul> <h3 id="spark-ml-library">Spark ML Library</h3> <ul> <li> <p>Spark makes possible to run Machine Learning workflows using their Spark ML library. This library can be divided into 4 key constituents:</p> <ul> <li><strong>Transformers</strong>: are mainly used to perform data engineering/pre-processing tasks (e.g.scaling, feature selection, etc…) and they just apply rule-based transformations (there is no learning from data). They take a <strong>data frame</strong> as input and return <strong>a new data frame</strong>.</li> <li> <p><strong>Estimators</strong>: learn parameters from the data and return a trained ML model (which is a Transformer).</p> </li> <li><strong>Pipeline</strong>: organizes a sequence of Transformers and Estimators in a single object.</li> <li><strong>Evaluators</strong>: used in order to assess our Machine Learning models through various classification, regression, etc… metrics.</li> </ul> </li> </ul>]]></content><author><name></name></author><summary type="html"><![CDATA[NumPy]]></summary></entry><entry><title type="html">Compilers Optimisation</title><link href="https://zihe33huang.github.io/blog/2023/Compilers-Optimisation/" rel="alternate" type="text/html" title="Compilers Optimisation"/><published>2023-02-28T00:00:00+00:00</published><updated>2023-02-28T00:00:00+00:00</updated><id>https://zihe33huang.github.io/blog/2023/Compilers-Optimisation</id><content type="html" xml:base="https://zihe33huang.github.io/blog/2023/Compilers-Optimisation/"><![CDATA[<h1 id="optimisation1">Optimisation1</h1> <h3 id="constant-folding">Constant folding</h3> <ul> <li>Where possible, replace variables with constants at compile time.</li> <li>Benefits: <ul> <li>Reduces memory references (value stored in instruction, rather than in data).</li> <li>Expressions that only involve constants <strong>can be evaluated at compile time</strong></li> <li>Take care with expressions which might result in errors (overflow, divide by zero)</li> <li>For floating point, must ensure that compiler will generate same results as executed code.</li> </ul> </li> </ul> <h3 id="algebraic-simplifications">Algebraic simplifications</h3> <ul> <li>Compiler can recognize and simplify algebraic expressions.</li> <li>Examples: ① i + 0 -&gt; i ② i * 0 -&gt; 0 ③ i ** 2 -&gt; i * I ④ (I - J) + (I - J) + (I - J) -&gt; 3 * I - 3 * J</li> </ul> <h3 id="copy-propagation">Copy propagation</h3> <ul> <li> <p>Given an assignment (<strong>x=y</strong>), we can replace later uses of <strong>x</strong> with <strong>y</strong>, provided no changes to either <strong>x</strong> or</p> <p><strong>y</strong> have occurred in the meantime.</p> </li> <li> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>x = y;  								  x = y;
c = x + 3;        ===&gt;   	c = y + 3;
d = x + y;   							d = y + y;
</code></pre></div> </div> </li> <li>==Benefits==: Can reduce memory references, or number of registers required</li> </ul> <h3 id="constant-propagation">Constant propagation</h3> <ul> <li> <p>If a variable <strong>x</strong> is assigned a constant value, then subsequent references to <strong>x</strong> can be replaced by the constant, provided no changes to <strong>x</strong> occur in the meantime. (假如x值在这期间没有被改变)</p> </li> <li> <p>==Benefits==: Reduce the number of registers required.</p> </li> <li> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>x = 4;									  x = 4;
c = x + 3;			  ===&gt; 		c = 4 + 3;
d = x + y; 								d = 4 + y;
</code></pre></div> </div> </li> </ul> <h3 id="redundancy-elimination">Redundancy elimination</h3> <ul> <li>removing redundant computations.</li> <li></li> </ul> <h1 id="instruction-scheduling-optimizations">Instruction scheduling optimizations</h1> <h3 id="introduction">Introduction</h3> <ul> <li> <p>It is important to remember that compiler is making transformations at level of individual machine instructions</p> </li> <li> <p>==Why instruction scheduling is important?==</p> <ul> <li> <p>Compiler code-generator translates <strong>IR(intermediate Representation)</strong> into sequences of hardware instructions</p> </li> <li> <p>Most modern processors use register/load-store instruction sets, load/store operations go between registers and memory.</p> </li> <li> <p>Most instructions take many cycles to complete but are pipelined</p> <ul> <li> <p>Processor can continue to issue new instruction until it needs to use the result of an incomplete operation</p> <p>(pipeline stalls waiting for source register to become ready)</p> </li> </ul> </li> </ul> </li> <li> <p>Dependency graph</p> <ul> <li><strong>Values</strong> in registers represent the dependencies between instructions (forms a graph)</li> <li>Instructions can be issued in any order that preserves dependency order.</li> <li>Compiler wants to choose schedule to leave enough time between issue and result-use to ==<strong>prevent pipeline stall</strong>==</li> <li>A = (B * C) + (D * E). Instructions are nodes, Value(Registers) are vertexes.</li> </ul> </li> </ul> <p><img src="images/image-20230228203933140.png" alt="image-20230228203933140" style="zoom:50%;"/></p> <h3 id="loop-unrolling">Loop unrolling</h3> <ul> <li>Problem: Loops with small bodies generate small basic blocks of assembly code <ul> <li>lot of dependencies between instructions</li> <li>high branch frequency</li> <li>little scope for good <strong>instruction scheduling</strong></li> </ul> </li> <li>The above is why we need loop unrolling. Loop unrolling is a technique for increasing the size of the loop body <ul> <li>gives more scope for better schedules</li> <li>reduces branch frequency</li> <li>make more independent instructions available for multiple issue.</li> </ul> </li> <li>Details: <ul> <li>Replace loop body by multiple copies of the body</li> <li>Modify loop control, but remember to take care of arbitrary loop bounds</li> <li>Number of copies is called ==<strong>unroll factor</strong>==</li> <li></li> </ul> </li> </ul> <h1 id="data-cache-optimization">Data cache optimization</h1>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Mysql Index</title><link href="https://zihe33huang.github.io/blog/2023/Mysql-Index/" rel="alternate" type="text/html" title="Mysql Index"/><published>2023-02-28T00:00:00+00:00</published><updated>2023-02-28T00:00:00+00:00</updated><id>https://zihe33huang.github.io/blog/2023/Mysql-Index</id><content type="html" xml:base="https://zihe33huang.github.io/blog/2023/Mysql-Index/"><![CDATA[<p>https://zhuanlan.zhihu.com/p/149287061</p> <h1 id="b-tree">B+ Tree</h1> <p>https://en.wikipedia.org/wiki/B%2B_tree</p> <p>https://byjus.com/gate/b-plus-tree-in-dbms-notes/</p> <p>http://blog.codinglabs.org/articles/theory-of-mysql-index.html 这个复习的时候再看几遍</p> <h3 id="features">Features</h3> <ul> <li>All records are only stored in <strong>leaf nodes</strong>, <strong>internal nodes</strong> are <strong>used for searching leaf nodes. **(所有数据都在叶子节点， 中间结点用来搜索). **More Branching</strong> of internal nodes helps to reduce the height of tree. (中间结点的分支越多，或者说孩子越多，树的高度就越小)</li> <li>All leaf nodes are at the same height, and are linked sequentially by a <strong>linked list</strong> (叶子结点的高度一致, 且所有叶子结点由一个链表连起来)</li> <li><strong>Order</strong> or <strong>branching factor</strong>. The maximum allowed number of direct child nodes. (树的阶, 最大孩子数)</li> <li>具体的节点的关系看wiki百科</li> </ul> <h3 id="pros">Pros</h3> <ul> <li>The query is <strong>stable</strong>, Records can be retrieved in an equal number of disks access. Reason: all leaf nodes at same height</li> <li><strong>Low cost</strong> of disk read and write. Reason: Internal nodes don’t store the data, only pointer.</li> <li>The number of disk I/O is low. Reason: The height of tree is low</li> <li>Better for <strong>Range query</strong>. Reason: Linked List in leaf nodes.</li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/images/image-20230228011302575-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/images/image-20230228011302575-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/images/image-20230228011302575-1400.webp"/> <img src="/images/image-20230228011302575.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h3 id="database-related">Database Related</h3> <ul> <li>One Node memory size is equal to one page size.</li> </ul> <h1 id="clustered-index">clustered index</h1> <p><img src="images/image-20230228012143000.png" alt="image-20230228012143000"/></p>]]></content><author><name></name></author><category term="Mysql"/><summary type="html"><![CDATA[https://zhuanlan.zhihu.com/p/149287061]]></summary></entry><entry><title type="html">Weekly English. Week1</title><link href="https://zihe33huang.github.io/blog/2023/Weekly-English/" rel="alternate" type="text/html" title="Weekly English. Week1"/><published>2023-02-27T00:00:00+00:00</published><updated>2023-02-27T00:00:00+00:00</updated><id>https://zihe33huang.github.io/blog/2023/Weekly-English</id><content type="html" xml:base="https://zihe33huang.github.io/blog/2023/Weekly-English/"><![CDATA[<h1 id="vocabulary-i-dont-know-meaning">vocabulary I don’t know meaning</h1> <p>complimentary adj. 赞美的 免费赠送的</p> <p>magnify v. 放大的</p> <p>Canary Wharf 金丝雀码头</p> <p>Vomit 呕吐</p> <p>Gravy 肉汁</p> <p>Recap 扼要的重述</p> <p>Hellish 地狱般的</p> <p>Shares tank 彻底失败 破产</p> <p>Clip (影片) 片段</p> <h1 id="vocabulary-im-not-familiar-with-listening">vocabulary I’m not familiar with listening</h1> <p>Monopoly</p>]]></content><author><name></name></author><category term="English Learning"/><summary type="html"><![CDATA[vocabulary I don’t know meaning]]></summary></entry><entry><title type="html">Container &amp;amp; hpc</title><link href="https://zihe33huang.github.io/blog/2023/container-&-HPC/" rel="alternate" type="text/html" title="Container &amp;amp; hpc"/><published>2023-02-27T00:00:00+00:00</published><updated>2023-02-27T00:00:00+00:00</updated><id>https://zihe33huang.github.io/blog/2023/container%20&amp;%20HPC</id><content type="html" xml:base="https://zihe33huang.github.io/blog/2023/container-&amp;-HPC/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">JVM memory management</title><link href="https://zihe33huang.github.io/blog/2023/jvm-memory-management/" rel="alternate" type="text/html" title="JVM memory management"/><published>2023-02-26T00:00:00+00:00</published><updated>2023-02-26T00:00:00+00:00</updated><id>https://zihe33huang.github.io/blog/2023/jvm-memory-management</id><content type="html" xml:base="https://zihe33huang.github.io/blog/2023/jvm-memory-management/"><![CDATA[<h1 id="what-is-memory-management-in-java">What is memory management in Java</h1> <ul> <li>In C, C++, we programers need to keep watch of memory allocation.</li> <li>In Java, Garbage Collector has the duty of memory deallocation handling and it runs automatically.</li> </ul> <h1 id="jvm-memory-structure">JVM Memory Structure</h1> <ul> <li> <p><img src="images/image-20230227005117988.png" alt="image-20230227005117988" style="zoom:50%;"/></p> </li> <li>https://seagence.com/blog/memory-management-java/</li> <li>https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-2.html#jvms-2.5.4</li> <li>https://www.yuque.com/u21195183/jvm/nbkm46</li> </ul> <h4 id="heap-memory">Heap Memory</h4> <ul> <li>Shared runtime data area that can be allocated to all objects and arrays, including class objects.</li> <li>VM options to configure head size: <ul> <li>Maximum Java heap size: -Xmx</li> <li>Initial Java heap size: -Xms</li> </ul> </li> </ul> <h4 id="jvm-stack-area">JVM Stack Area</h4> <ul> <li> <p>Private.</p> </li> <li>A stack is created simultaneously with the creation of a thread.</li> <li> <font color="red">**Fixed Size**</font> <p>. If the computation in a thread requires a larger Java Virtual Machine stack than is permitted, the Java Virtual Machine throws a <code class="language-plaintext highlighter-rouge">StackOverflowError</code></p> </li> <li> <font color="red">**Auto expanded size**</font> <p>. If Java Virtual Machine stacks can be dynamically expanded, and expansion is attempted but insufficient memory can be made available to effect the expansion, or if insufficient memory can be made available to create the initial Java Virtual Machine stack for a new thread, the Java Virtual Machine throws an <code class="language-plaintext highlighter-rouge">OutOfMemoryError</code>.</p> </li> </ul> <h5 id="stack-frame-contains">Stack Frame contains</h5> <ul> <li>Local Variable array 本地变量表</li> <li>Frame Data</li> <li>Operand Stack 操作数栈</li> <li> <p>Dynamic linking</p> </li> <li>The sizes of LVA, FD and OS are <font color="red">**determined at the compile time** </font></li> <li>每个线程只能有一个活动栈帧（current frame, active frame) ，对应着当前正在执行的那个方法.</li> </ul> <h5 id="does-gc-involve-jvm-stack-area">Does GC involve JVM Stack Area?</h5> <ul> <li>No. The memory on the stack contains <strong>method-parameters</strong> and <strong>local variables</strong> (to be precise: the references for objects and variables itself for primitive types). <strong>The memory will be automatically removed if you leave the method</strong>.</li> </ul> <h5 id="is-local-variables-thread-safe">Is local variables thread safe?</h5> <ul> <li> <p>Every thread has its own JVM stack and never share its stack with other thread.</p> </li> <li> <p>But local references to objects are a bit different. The reference itself is not shared. The object referenced however, is not stored in each threads’s local stack. All objects are stored in the shared heap.</p> <p><strong>①</strong> If an object created locally never escapes the method it was created in, it is thread safe.</p> <p><strong>②</strong> But if it escapes from the method, we need to consider thread safe.</p> </li> </ul> <h4 id="program-counter-pc-register">Program counter (PC) register</h4> <ul> <li> <p>Private</p> </li> <li> <p>Storing the address of the next instruction.</p> </li> <li> <p>No GC and OOM</p> </li> <li> <p>Why we need it</p> <ul> <li> <p>There are many threads in JVM, <font color="red">context switch </font>will frequently happen, with PC register, CPU know where to execute.</p> </li> <li>Context Switch: In computing, a context <em>switch</em> is the process of storing the state of a process or <em>thread</em>, so that it can be restored and resume execution at a later point.</li> <li></li> </ul> </li> </ul> <h4 id="method-area">Method Area</h4> <ul> <li>Create as JVM starts up.</li> <li>The size of method area determine how many classes can be stored, if there are too many classes in system, memory can not be made available to satisfy memory allocation, <strong>JVM will throws OOM</strong> <ul> <li>加载大量第三方jar包。 Tomcat部署工程过多。 大量动态的生成反射类。</li> </ul> </li> <li>元空间: metaspace 永久代: PermGen Permanent Generation <ul> <li>Diff: https://www.baeldung.com/java-permgen-metaspace</li> </ul> </li> </ul>]]></content><author><name></name></author><category term="jvm"/><summary type="html"><![CDATA[What is memory management in Java]]></summary></entry><entry><title type="html">JVM review</title><link href="https://zihe33huang.github.io/blog/2023/jvm_garbage_collection/" rel="alternate" type="text/html" title="JVM review"/><published>2023-02-26T00:00:00+00:00</published><updated>2023-02-26T00:00:00+00:00</updated><id>https://zihe33huang.github.io/blog/2023/jvm_garbage_collection</id><content type="html" xml:base="https://zihe33huang.github.io/blog/2023/jvm_garbage_collection/"><![CDATA[<h3 id="how-to-tell-if-an-object-is-alive">How to tell if an object is alive?</h3> <ol> <li> <p>Reference counting.</p> <ul> <li> <p>Consider an object to be alive as long as the number of references to that object is greater than zero.</p> </li> <li> <p>Can not <strong>reclaim</strong> cyclic reference.</p> </li> </ul> </li> <li> <p>Reachability analysis</p> <ul> <li>Traverse the object graph recursively from <strong>GC roots</strong>.</li> <li>GC roots: <ul> <li>Live Thread.</li> <li>Static variables.</li> <li>Local variables</li> <li>Objects in JNI (Java native interface) native method stack.</li> <li>Objects used as monitors for synchronization</li> </ul> </li> </ul> </li> </ol> <p>###</p>]]></content><author><name></name></author><category term="jvm"/><summary type="html"><![CDATA[How to tell if an object is alive?]]></summary></entry><entry><title type="html">Displaying External Posts on Your al-folio Blog</title><link href="https://zihe33huang.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/" rel="alternate" type="text/html" title="Displaying External Posts on Your al-folio Blog"/><published>2022-04-23T23:20:09+00:00</published><updated>2022-04-23T23:20:09+00:00</updated><id>https://zihe33huang.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog</id><content type="html" xml:base="https://zihe33huang.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/"><![CDATA[]]></content><author><name></name></author></entry></feed>